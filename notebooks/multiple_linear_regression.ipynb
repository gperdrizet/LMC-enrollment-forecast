{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "652492cb-365b-47e1-95f9-cf48561614fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (config.py, line 32)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/siderealyear/anaconda3/envs/LMC-enrollment-forecast/lib/python3.8/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3437\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-a5efaa244a22>\"\u001b[0;36m, line \u001b[0;32m20\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    import config as conf\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"../config.py\"\u001b[0;36m, line \u001b[0;32m32\u001b[0m\n\u001b[0;31m    NEURAL_NETWORK_MODEL_ENSEMBLE_FILE 'neural_network_model_ensemble_file.pkl'\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.core.common import flatten\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Add parent directory to path to allow import of config.py\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import config as conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71be6a23-5801-40d8-9e5b-624cc55744d0",
   "metadata": {},
   "source": [
    "First modeling strategy attempted will be a simple linear model which predicts the next term's enrollment based on all of the previous term's data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1679ec6-0156-4e3f-a21e-49ca17fe95e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(f'{conf.DATA_PATH}{conf.FORMATTED_DATAFILE}')\n",
    "\n",
    "# Seperate independent & dependent variables\n",
    "X = data.drop(conf.TARGET_VARIABLE, axis=1)\n",
    "y = data[conf.TARGET_VARIABLE]\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f901c73-ab72-45b6-bd4b-25c9798b2d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit a LinearRegression object\n",
    "lm = LinearRegression()\n",
    "linear_model = lm.fit(X, y)\n",
    "\n",
    "# Predict enrollment\n",
    "predicted_enrollment = lm.predict(X)\n",
    "\n",
    "# Grab actual enrollment numbers to compare with\n",
    "actual_enrollment = y\n",
    "\n",
    "# Plot actual enrollment vs predicted enrollment\n",
    "sns.set(rc={'figure.figsize':(8,8)})\n",
    "ax = sns.regplot(y=predicted_enrollment, x=actual_enrollment, fit_reg=True, scatter_kws={'s':60})\n",
    "ax.tick_params(labelsize=12)\n",
    "ax.set_title('Predicted vs actual enrollment', fontsize=18)\n",
    "ax.set_xlabel('Actual enrollment', fontsize=14)\n",
    "ax.set_ylabel('Predicted enrollment', fontsize=15)\n",
    "ax.set_xlim(4000, 27000)\n",
    "ax.set_ylim(4000, 27000)\n",
    "ax.yaxis.set_major_formatter(FormatStrFormatter('%.0f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a24dfc4-113d-4d7f-98f7-ed0e19716b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score model\n",
    "scikit_R_sqr = linear_model.score(X, actual_enrollment)\n",
    "MAE = mean_absolute_error(y, predicted_enrollment)\n",
    "print('SciKit-learn R\\u00b2: {}'.format(np.round(scikit_R_sqr, 3)))\n",
    "print(f'Mean absolute error: {int(MAE)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8f2b7d",
   "metadata": {},
   "source": [
    "Looks too good to be true, right? Yes, it is - this is just over-fitting, plain and simple. We have no idea how well this model will generalize to new data and no reason to expect that it will at all. To do this right we need to split the data up into a training and test set so we can get an estimate of how our model will perform on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac30eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data randomly into training and testing sets\n",
    "training_data = data.sample(frac=conf.TRAIN_TEST_SPLIT)\n",
    "test_data = data.drop(training_data.index)\n",
    "\n",
    "# Seperate dependent and independent variable\n",
    "training_features = training_data.copy()\n",
    "test_features = test_data.copy()\n",
    "\n",
    "training_labels = training_features.pop(conf.TARGET_VARIABLE)\n",
    "test_labels = test_features.pop(conf.TARGET_VARIABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f32ec6-3757-4cde-9fdc-cf369addd8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit a LinearRegression object\n",
    "lm = LinearRegression()\n",
    "linear_model = lm.fit(training_features, training_labels)\n",
    "\n",
    "# Predict enrollment\n",
    "predicted_enrollment = lm.predict(test_features)\n",
    "\n",
    "# Grab actual enrollment numbers to compare with\n",
    "actual_enrollment = test_labels\n",
    "\n",
    "# Plot actual enrollment vs predicted enrollment\n",
    "sns.set(rc={'figure.figsize':(8,8)})\n",
    "\n",
    "ax = sns.regplot(\n",
    "    y=predicted_enrollment, \n",
    "    x=actual_enrollment, \n",
    "    fit_reg=True, \n",
    "    ci=False, \n",
    "    scatter_kws={'s':60}\n",
    ")\n",
    "\n",
    "ax.tick_params(labelsize=12)\n",
    "ax.set_title('Predicted vs actual enrollment', fontsize=18)\n",
    "ax.set_xlabel('Actual enrollment', fontsize=14)\n",
    "ax.set_ylabel('Predicted enrollment', fontsize=15)\n",
    "# ax.set_xlim(4000, 27000)\n",
    "# ax.set_ylim(4000, 27000)\n",
    "ax.yaxis.set_major_formatter(FormatStrFormatter('%.0f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d23e675",
   "metadata": {},
   "outputs": [],
   "source": [
    "scikit_R_sqr = linear_model.score(test_features, actual_enrollment)\n",
    "MAE = mean_absolute_error(test_labels, predicted_enrollment)\n",
    "print('SciKit-learn R\\u00b2: {}'.format(np.round(scikit_R_sqr, 3)))\n",
    "print(f'Mean absolute error: {int(MAE)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53a583a",
   "metadata": {},
   "source": [
    "Ouch! Now it looks terrible... and we see the problem. With this small of a dataset we can predict 'memorize' the training set just fine, but the model does not generalize to unseen data at all.\n",
    "\n",
    "Let's see if we can improve using bootstrap aggregation - the plan will be to train multiple models on multiple randomly chosen subsets of the data and then use the resulting ensemble of models to make predictions. First step is to encapsulate the above operations into functions so we can easily repeat them inside of a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe7dd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(data, training_data_fraction, label_column_name):\n",
    "    '''Takes master data as pandas dataframe splits into train and\n",
    "    test features and labels, returns a dict of dataframes'''\n",
    "    \n",
    "    # Split data randomly into training and testing sets\n",
    "    training_data = data.sample(frac=training_data_fraction)\n",
    "    test_data = data.drop(training_data.index)\n",
    "\n",
    "    # Seperate dependent and independent variable\n",
    "    training_features = training_data.copy()\n",
    "    test_features = test_data.copy()\n",
    "\n",
    "    training_labels = training_features.pop(label_column_name)\n",
    "    test_labels = test_features.pop(label_column_name)\n",
    "    \n",
    "    dataset = {}\n",
    "    dataset['training_features'] = training_features\n",
    "    dataset['test_features'] = test_features\n",
    "    dataset['training_labels'] = training_labels\n",
    "    dataset['test_labels'] = test_labels\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364846af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_linear_model(data):\n",
    "    '''Takes dataset dict, returns fit linear model'''\n",
    "    \n",
    "    # Create and fit a LinearRegression object\n",
    "    lm = LinearRegression()\n",
    "    linear_model = lm.fit(dataset['training_features'], dataset['training_labels'])\n",
    "    \n",
    "    return lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40717581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First make some empty lists to hold our trained models and other results\n",
    "results = {}\n",
    "results['trained_linear_models'] = []\n",
    "results['test_set_scores'] = []\n",
    "results['test_set_labels'] = []\n",
    "results['test_set_features'] = []\n",
    "results['test_set_predictions'] = []\n",
    "\n",
    "# Outer training loop\n",
    "for i in range(conf.N_MODELS):\n",
    "    print(f'Training model {i}', end='\\r')\n",
    "    \n",
    "    # Make dataset\n",
    "    dataset = create_datasets(\n",
    "        data,\n",
    "        conf.TRAIN_TEST_SPLIT,\n",
    "        conf.TARGET_VARIABLE\n",
    "    )\n",
    "    \n",
    "    # Fit the model to the training portion of the dataset\n",
    "    linear_model = fit_linear_model(dataset)\n",
    "    \n",
    "    # Use the trained model to make predictions from the test set features\n",
    "    predictions = linear_model.predict(test_features)\n",
    "    \n",
    "    test_score = mean_absolute_error(dataset['test_labels'], predictions)\n",
    "    \n",
    "    # Sanity check model score\n",
    "    if test_score < 1000000:\n",
    "        # Store results\n",
    "        results['trained_linear_models'].append(linear_model)\n",
    "\n",
    "        # Add test set score to list\n",
    "        results['test_set_scores'].append(test_score)\n",
    "\n",
    "        # Add test set predictions and labels to list\n",
    "        results['test_set_predictions'].extend(list(flatten(predictions)))\n",
    "        results['test_set_labels'].extend(dataset['test_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8d4002-b5f8-410f-8066-0f964ff1c9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model ensemble\n",
    "pkl_filename = f'{conf.RESULTS_PATH}{conf.MULTIPLE_LINEAR_MODEL_RESULTS_FILE}'\n",
    "\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3f08c1",
   "metadata": {},
   "source": [
    "Cool - now we have a ensemble of models which were each fit on a randomly chosen test/train split of the data - we also have a distribution of test set scores. Lets plot it and take a look at how we are faring. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89099bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of MAE scores from each model\n",
    "sns.displot(results['test_set_scores'], kind=\"kde\")\n",
    "plt.xlabel('Mean absolute error')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7add563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Avg test set MAE: {int(mean(results[\"test_set_scores\"]))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa446870",
   "metadata": {},
   "source": [
    "Not that great to be honest - but at least now we have some idea of the error distribution. For example - if we had stuck with the one-off model and gotten lucky on the test/train split, we could have ended up with near zero MAE and thought we had a crystal ball on our hands, only to be badly disapointed in our predictions when next semester rolled arround.\n",
    "\n",
    "Let's try and make a prediction with the ensemble so we have something to compare to later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3da511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split master data into features and labels\n",
    "X = data.drop(conf.TARGET_VARIABLE, axis=1)\n",
    "y = data[conf.TARGET_VARIABLE]\n",
    "\n",
    "# Empty list to hold predictions\n",
    "predictions = []\n",
    "\n",
    "for linear_model in results['trained_linear_models']:\n",
    "    predicted_enrollment = linear_model.predict(X)\n",
    "    predictions.append(predicted_enrollment)\n",
    "\n",
    "# Average the predictions from each model\n",
    "predicted_enrollment = np.mean(np.array(predictions), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1637c025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab actual enrollment numbers to compare with\n",
    "actual_enrollment = y\n",
    "\n",
    "# Plot actual enrollment vs predicted enrollment\n",
    "sns.set(rc={'figure.figsize':(8,8)})\n",
    "\n",
    "ax = sns.regplot(\n",
    "    y=predicted_enrollment, \n",
    "    x=actual_enrollment, \n",
    "    fit_reg=True, \n",
    "    ci=False, \n",
    "    scatter_kws={'s':60}\n",
    ")\n",
    "\n",
    "ax.tick_params(labelsize=12)\n",
    "ax.set_title('Predicted vs actual enrollment', fontsize=18)\n",
    "ax.set_xlabel('Actual enrollment', fontsize=14)\n",
    "ax.set_ylabel('Predicted enrollment', fontsize=15)\n",
    "# ax.set_xlim(4000, 27000)\n",
    "# ax.set_ylim(4000, 27000)\n",
    "ax.yaxis.set_major_formatter(FormatStrFormatter('%.0f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa667aa",
   "metadata": {},
   "source": [
    "Just for completeness, lets set up to construct a confidence interval arround our predictions using our model ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c48b507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick one semester to predict\n",
    "single_semester = data.iloc[5]\n",
    "\n",
    "# Seperate independent & dependent variables\n",
    "X = single_semester.drop(conf.TARGET_VARIABLE)\n",
    "X = np.array(X).reshape(1, -1)\n",
    "\n",
    "y = single_semester[conf.TARGET_VARIABLE]\n",
    "\n",
    "# Empty list to hold predictions\n",
    "predictions = []\n",
    "\n",
    "# Make prediction with each model\n",
    "for linear_model in results['trained_linear_models']:\n",
    "    predicted_enrollment = linear_model.predict(X)\n",
    "    predictions.extend(predicted_enrollment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6cea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of predictions from each model\n",
    "sns.displot(predictions, kind=\"kde\")\n",
    "plt.xlabel('Enrollment')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391191ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "\n",
    "mean = np.mean(predictions)\n",
    "low, high = st.norm.interval(alpha=0.95, loc=np.mean(predictions), scale=st.sem(predictions))\n",
    "\n",
    "print(f'Mean: {int(mean)}, 95% CI: {int(low)}-{int(high)}')\n",
    "print(f'True value: {int(y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b72e4ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

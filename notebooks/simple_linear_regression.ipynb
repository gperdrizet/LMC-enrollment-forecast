{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13c7d830-fd04-40e8-8809-e6b24eef29ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (config.py, line 32)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/siderealyear/anaconda3/envs/LMC-enrollment-forecast/lib/python3.8/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3437\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-b848f640fbd1>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    import config as conf\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"../config.py\"\u001b[0;36m, line \u001b[0;32m32\u001b[0m\n\u001b[0;31m    NEURAL_NETWORK_MODEL_ENSEMBLE_FILE 'neural_network_model_ensemble_file.pkl'\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Add parent directory to path to allow import of config.py\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import config as conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18859894-4bcd-437d-8b43-d51d6e62ddc9",
   "metadata": {},
   "source": [
    "For our baseline or 'naive' model, we will use a simple linear regression model on enrolment as a function of time. This model is not expected to perform well, but it will give us a baseline for the simplest possible model to compare other models to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaedf83-1a60-4c4a-b5c5-174ed6d9a6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(f'{conf.DATA_PATH}{conf.CLEANED_DATAFILE}')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291c3138-0b95-4384-89c6-d53db7a3bdd0",
   "metadata": {},
   "source": [
    "To do a simple x, y linear fit, we first need to do a little data formatting. The goal is to make a timeseries where the date is x and enrollment is y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9046eaa5-591f-4ba1-9886-c4677a7ad505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_semester_strings(semesters):\n",
    "    '''Takes a list of semester string identifiers and translates\n",
    "    them into month and day of census. Returns two lists with month\n",
    "    and day numbers'''\n",
    "    \n",
    "    census_months = []\n",
    "    census_days = []\n",
    "\n",
    "    for semester in list(semesters):\n",
    "\n",
    "        if semester == 'FA':\n",
    "            census_months.append(9)\n",
    "            census_days.append(8)\n",
    "\n",
    "        elif semester == 'SP':\n",
    "            census_months.append(2)\n",
    "            census_days.append(8)\n",
    "\n",
    "        elif semester == 'SU':\n",
    "            census_months.append(5)\n",
    "            census_days.append(14)\n",
    "\n",
    "    return census_months, census_days\n",
    "\n",
    "def make_xy_data(data):\n",
    "    '''Wapper function takes formatted data and recovers two lists - one of census enrollment\n",
    "    numbers (returned as y) and the census data (returned as x)'''\n",
    "    \n",
    "#     global years\n",
    "#     years = data.filter(regex=(\"year.*\"))\n",
    "    \n",
    "#     global semesters\n",
    "#     semesters = data.filter(regex=(\"semester.*\"))\n",
    "\n",
    "#     decoded_years = years.apply(decode_year, axis=1)\n",
    "#     decoded_semesters = semesters.apply(decode_semester, axis=1)\n",
    "\n",
    "    census_months, census_days = decode_semester_strings(data['semester'])\n",
    "\n",
    "    x = pd.to_datetime(dict(year=data['year'], month=census_months, day=census_days))\n",
    "    y = data['Census Enrollment']\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495415e3-1f48-4f9d-a268-ac9b87e420e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get census data and corresponding enrollment number from\n",
    "# each row in the data\n",
    "\n",
    "x, y = make_xy_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c648ba9-c2af-459d-9d6f-aa4dff794961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot enrollment numbers over time\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(x, y, color='black')\n",
    "plt.axis([None, None, 0, 30000])\n",
    "plt.xticks(rotation = 45)\n",
    "fig.suptitle('Census Enrollment', fontsize=20)\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Enrollment', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5449c205-56cc-4970-8b7c-2621fccbd4da",
   "metadata": {},
   "source": [
    "The orignal plan was to fit this data with one line and call that the minimal model. But looking at the data, I think that is going a bit to far in terms of oversimplifying on purpose to make the other models look good. I think that what we have to do is use two linear fits, one to summer semesters and the other to fall and spring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31075f0-a61f-4308-9ab8-fe0c87f36275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into summer and fall-spring sets, then remake x, y data for each\n",
    "\n",
    "SU_data = data[data['semester'] == \"SU\"]\n",
    "SU_x, SU_y = make_xy_data(SU_data)\n",
    "\n",
    "FA_SP_data = data[data['semester'] != \"SU\" ]\n",
    "FA_SP_x, FA_SP_y = make_xy_data(FA_SP_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705e6fb3-0f09-4c07-82fc-e9239485d333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replot census enrollment over time as two series\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(SU_x, SU_y, c='green', label='Summer')\n",
    "plt.scatter(FA_SP_x, FA_SP_y, c='black', label='Fall, Spring')\n",
    "plt.legend(loc='upper left')\n",
    "plt.axis([None, None, 0, 30000])\n",
    "plt.xticks(rotation = 45)\n",
    "fig.suptitle('Census Enrollment', fontsize=20)\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Enrollment', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea046e6-1e36-4d1b-b925-3048cd7ee872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear models to the summer and fall-spring data, then make\n",
    "# predictions from the respective x vectors\n",
    "\n",
    "# Convert pandas datatime to ms timestamp\n",
    "SU_x_timestamp = SU_x.values.astype(np.int64) // 10 ** 9\n",
    "FA_SP_x_timestamp = FA_SP_x.values.astype(np.int64) // 10 ** 9\n",
    "\n",
    "# Reshape and convert to numpy array\n",
    "SU_x_timestamp = np.array(SU_x_timestamp).reshape(-1, 1)\n",
    "FA_SP_x_timestamp = np.array(FA_SP_x_timestamp).reshape(-1, 1)\n",
    "\n",
    "# Fit linear models\n",
    "SU_linear_model = LinearRegression().fit(SU_x_timestamp, SU_y)\n",
    "FA_SP_linear_model = LinearRegression().fit(FA_SP_x_timestamp, FA_SP_y)\n",
    "\n",
    "# Use models to make predictions\n",
    "SU_predictions = SU_linear_model.predict(SU_x_timestamp)\n",
    "FA_SP_predictions = FA_SP_linear_model.predict(FA_SP_x_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22efd49d-c8c8-4537-ac98-bf49d753024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replot census enrollment over time as two series\n",
    "# with linear fits\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(SU_x, SU_y, c='green', label='Summer')\n",
    "plt.plot(SU_x, SU_predictions, c='green')\n",
    "plt.scatter(FA_SP_x, FA_SP_y, c='black', label='Fall, Spring')\n",
    "plt.plot(FA_SP_x, FA_SP_predictions, c='black')\n",
    "plt.legend(loc='upper left')\n",
    "plt.axis([None, None, 0, 30000])\n",
    "plt.xticks(rotation = 45)\n",
    "fig.suptitle('Census Enrollment', fontsize=20)\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Enrollment', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688e45c5-9bf9-407f-ad37-9071e51c3662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score summer model\n",
    "SU_scikit_R_sqr = SU_linear_model.score(SU_x_timestamp, SU_y)\n",
    "SU_MAE = mean_absolute_error(SU_y, SU_predictions)\n",
    "print('SciKit-learn R\\u00b2: {}'.format(np.round(SU_scikit_R_sqr, 3)))\n",
    "print(f'Mean absolute error: {int(SU_MAE)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e7c22d-5b10-4538-b3ba-b835d8f4293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score winter/fall model\n",
    "FA_SP_scikit_R_sqr = FA_SP_linear_model.score(FA_SP_x_timestamp, FA_SP_y)\n",
    "FA_SP_MAE = mean_absolute_error(FA_SP_y, FA_SP_predictions)\n",
    "print('SciKit-learn R\\u00b2: {}'.format(np.round(FA_SP_scikit_R_sqr, 3)))\n",
    "print(f'Mean absolute error: {int(FA_SP_MAE)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c852b69-1628-488d-8859-fe4c2fdd73ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get aggragate MAE for both models\n",
    "n_SU_points = len(SU_predictions)\n",
    "n_FA_SP_points = len(FA_SP_predictions)\n",
    "n = n_SU_points + n_FA_SP_points\n",
    "\n",
    "MAE = int((SU_MAE*(n_SU_points/n)) + (FA_SP_MAE*(n_FA_SP_points/n)))\n",
    "print(f'Aggregate MAE: {MAE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c502d31-d8bd-4cce-9cec-4d61be2cf041",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.scatter(SU_y, SU_predictions, c='green', label='Summer')\n",
    "plt.scatter(FA_SP_y, FA_SP_predictions, c='black', label='Fall, Spring')\n",
    "plt.legend(loc='upper left')\n",
    "plt.axis([None, None, 0, 30000])\n",
    "fig.suptitle('Census Enrollment', fontsize=20)\n",
    "plt.xlabel('Actual enrollment', fontsize=18)\n",
    "plt.ylabel('Predicted enrollment', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d5b02d-691a-4a91-a8aa-ebe206371c5d",
   "metadata": {},
   "source": [
    "OK - looks pretty good. The one caveat here is we have used all of the data in the fit. Therefore we don't know how well these models will generalize. Let't try again with a train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c20c3d-3851-4485-8d37-cb48c7af98aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split fall-spring data\n",
    "\n",
    "# Combine data into one dataframe\n",
    "FA_SP_data = pd.DataFrame(list(zip(FA_SP_x, FA_SP_y)),columns =['date', 'enrollment'])\n",
    "\n",
    "# Split data randomly into training and testing sets\n",
    "FA_SP_training_data = FA_SP_data.sample(frac=conf.TRAIN_TEST_SPLIT)\n",
    "FA_SP_test_data = FA_SP_data.drop(FA_SP_training_data.index)\n",
    "\n",
    "# Seperate dependent and independent variable\n",
    "FA_SP_training_x = FA_SP_training_data.copy()\n",
    "FA_SP_test_x = FA_SP_test_data.copy()\n",
    "\n",
    "FA_SP_training_y = FA_SP_training_x.pop('enrollment')\n",
    "FA_SP_test_y = FA_SP_test_x.pop('enrollment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24667949-cbf8-41f8-89e9-b10f4ef8babc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split summer data\n",
    "\n",
    "# Combine data into one dataframe\n",
    "SU_data = pd.DataFrame(list(zip(SU_x, SU_y)),columns =['date', 'enrollment'])\n",
    "\n",
    "# Split data randomly into training and testing sets\n",
    "SU_training_data = SU_data.sample(frac=conf.TRAIN_TEST_SPLIT)\n",
    "SU_test_data = SU_data.drop(SU_training_data.index)\n",
    "\n",
    "# Separate dependent and independent variable\n",
    "SU_training_x = SU_training_data.copy()\n",
    "SU_test_x = SU_test_data.copy()\n",
    "\n",
    "SU_training_y = SU_training_x.pop('enrollment')\n",
    "SU_test_y = SU_test_x.pop('enrollment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28a99ea-4f5c-4eba-a257-94c69962c151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-fit linear models to the summer and fall-spring training \n",
    "# data, then make predictions for the test sets\n",
    "\n",
    "# Convert pandas datatime to ms timestamp\n",
    "SU_training_x_timestamp = SU_training_x.values.astype(np.int64) // 10 ** 9\n",
    "FA_SP_training_x_timestamp = FA_SP_training_x.values.astype(np.int64) // 10 ** 9\n",
    "\n",
    "SU_test_x_timestamp = SU_test_x.values.astype(np.int64) // 10 ** 9\n",
    "FA_SP_test_x_timestamp = FA_SP_test_x.values.astype(np.int64) // 10 ** 9\n",
    "\n",
    "# Reshape and convert to numpy array\n",
    "SU_training_x_timestamp = np.array(SU_training_x_timestamp).reshape(-1, 1)\n",
    "FA_SP_training_x_timestamp = np.array(FA_SP_training_x_timestamp).reshape(-1, 1)\n",
    "\n",
    "# Fit linear models\n",
    "SU_linear_model = LinearRegression().fit(SU_training_x_timestamp, SU_training_y)\n",
    "FA_SP_linear_model = LinearRegression().fit(FA_SP_training_x_timestamp, FA_SP_training_y)\n",
    "\n",
    "# Use models to make predictions\n",
    "SU_test_predictions = SU_linear_model.predict(SU_test_x_timestamp)\n",
    "FA_SP_test_predictions = FA_SP_linear_model.predict(FA_SP_test_x_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd74b9ef-804e-45c2-8210-2741798d02b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replot the models against the test data to get a feel\n",
    "# for how we would do against unseen data\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(SU_test_x, SU_test_y, c='green', label='Summer')\n",
    "plt.plot(SU_test_x, SU_test_predictions, c='green')\n",
    "plt.scatter(FA_SP_test_x, FA_SP_test_y, c='black', label='Fall, Spring')\n",
    "plt.plot(FA_SP_test_x, FA_SP_test_predictions, c='black')\n",
    "plt.legend(loc='upper left')\n",
    "plt.axis([None, None, 0, 30000])\n",
    "plt.xticks(rotation = 45)\n",
    "fig.suptitle('Census Enrollment', fontsize=20)\n",
    "plt.xlabel('Date', fontsize=18)\n",
    "plt.ylabel('Enrollment', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3d5aae-0178-4933-b507-6a00a775ed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score summer model on test set\n",
    "SU_scikit_R_sqr = SU_linear_model.score(SU_test_x_timestamp, SU_test_y)\n",
    "SU_MAE = mean_absolute_error(SU_test_y, SU_test_predictions)\n",
    "print('SciKit-learn R\\u00b2: {}'.format(np.round(SU_scikit_R_sqr, 3)))\n",
    "print(f'Mean absolute error: {int(SU_MAE)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafcbf1a-0c6c-4ab4-b200-6589f44803f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score fall-spring model on test set\n",
    "FA_SP_scikit_R_sqr = FA_SP_linear_model.score(FA_SP_test_x_timestamp, FA_SP_test_y)\n",
    "FA_SP_MAE = mean_absolute_error(FA_SP_test_y, FA_SP_test_predictions)\n",
    "print('SciKit-learn R\\u00b2: {}'.format(np.round(FA_SP_scikit_R_sqr, 3)))\n",
    "print(f'Mean absolute error: {int(FA_SP_MAE)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd8d102-c5de-4271-929a-b3928880e233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get aggragate MAE for both models\n",
    "n_SU_points = len(SU_test_predictions)\n",
    "n_FA_SP_points = len(FA_SP_test_predictions)\n",
    "n = n_SU_points + n_FA_SP_points\n",
    "\n",
    "MAE = int((SU_MAE*(n_SU_points/n)) + (FA_SP_MAE*(n_FA_SP_points/n)))\n",
    "print(f'Aggregate MAE: {MAE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ec2b93-4f82-4996-bee3-433219c85669",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.scatter(SU_test_y, SU_test_predictions, c='green', label='Summer')\n",
    "plt.scatter(FA_SP_test_y, FA_SP_test_predictions, c='black', label='Fall, Spring')\n",
    "plt.legend(loc='upper left')\n",
    "plt.axis([None, None, 0, 30000])\n",
    "fig.suptitle('Census Enrollment', fontsize=20)\n",
    "plt.xlabel('Actual enrollment', fontsize=18)\n",
    "plt.ylabel('Predicted enrollment', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45c3c69-7e8b-4e3e-9bd3-2cda0d9a77d5",
   "metadata": {},
   "source": [
    "OK, looking like the 'control' model is actually going to win! Let's bootstrap it and come up with some confidence intervals.\n",
    "\n",
    "To do that, we need to encapsulate the above operations in functions so that we can easily loop over them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67abe392-49af-4005-bfe9-253186f1b15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(x, y, training_data_fraction):\n",
    "    '''Takes x and y lists of data, combines then randomly \n",
    "    samples them. Returns a dict contatining train and test\n",
    "    x and y datasets'''\n",
    "\n",
    "    # Combine data into one dataframe\n",
    "    data = pd.DataFrame(list(zip(x, y)),columns =['date', 'enrollment'])\n",
    "\n",
    "    # Split data randomly into training and testing sets\n",
    "    training_data = data.sample(frac=training_data_fraction)\n",
    "    test_data = data.drop(training_data.index)\n",
    "\n",
    "    # Seperate dependent and independent variable\n",
    "    training_x = training_data.copy()\n",
    "    test_x = test_data.copy()\n",
    "\n",
    "    training_y = training_x.pop('enrollment')\n",
    "    test_y = test_x.pop('enrollment')\n",
    "    \n",
    "    dataset = {}\n",
    "    dataset['training_x'] = training_x\n",
    "    dataset['test_x'] = test_x\n",
    "    dataset['training_y'] = training_y\n",
    "    dataset['test_y'] = test_y\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def train_linear_model(dataset):\n",
    "    '''Takes dataset, trains simple linear model,\n",
    "    returns trained model'''\n",
    "    \n",
    "    # Extract data from dataset\n",
    "    training_x = dataset['training_x']\n",
    "    test_x = dataset['test_x']\n",
    "    training_y = dataset['training_y']\n",
    "    test_y = dataset['test_y']\n",
    "    \n",
    "    # Convert pandas datatime to ms timestamp\n",
    "    training_x_timestamp = training_x.values.astype(np.int64) // 10 ** 9\n",
    "    test_x_timestamp = test_x.values.astype(np.int64) // 10 ** 9\n",
    "\n",
    "    # Reshape and convert to numpy array\n",
    "    training_x_timestamp = np.array(training_x_timestamp).reshape(-1, 1)\n",
    "\n",
    "    # Fit linear model\n",
    "    linear_model = LinearRegression().fit(training_x_timestamp, training_y)\n",
    "\n",
    "    # Use models to make predictions\n",
    "    test_predictions = linear_model.predict(test_x_timestamp)\n",
    "    \n",
    "    return linear_model, test_predictions\n",
    "    \n",
    "def score_models(\n",
    "    SU_y, \n",
    "    SU_predictions,\n",
    "    FA_SP_y,\n",
    "    FA_SP_predictions\n",
    "):\n",
    "    '''Calculates aggragate MAE for both models using weighted avg.'''\n",
    "    \n",
    "    SU_MAE = mean_absolute_error(SU_y, SU_predictions)\n",
    "    FA_SP_MAE = mean_absolute_error(FA_SP_y, FA_SP_predictions)\n",
    "    n_SU_points = len(SU_predictions)\n",
    "    n_FA_SP_points = len(FA_SP_predictions)\n",
    "    n = n_SU_points + n_FA_SP_points\n",
    "\n",
    "    MAE = int((SU_MAE*(n_SU_points/n)) + (FA_SP_MAE*(n_FA_SP_points/n)))\n",
    "    \n",
    "    return MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe4720b-20b7-4ff3-bfa5-ed211e1d0691",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "results['test_set_scores'] = []\n",
    "results['SU_models'] = []\n",
    "results['FA_SP_models'] = []\n",
    "results['test_labels'] = []\n",
    "results['test_features'] = []\n",
    "results['test_predictions'] = []\n",
    "\n",
    "# Outer training loop\n",
    "for i in range(conf.N_MODELS):\n",
    "    print(f'Training model {i}', end='\\r')\n",
    "    \n",
    "    SU_dataset = train_test_split(SU_x, SU_y, conf.TRAIN_TEST_SPLIT)\n",
    "    FA_SP_dataset = train_test_split(FA_SP_x, FA_SP_y, conf.TRAIN_TEST_SPLIT)\n",
    "    \n",
    "    SU_model, SU_test_predictions = train_linear_model(SU_dataset)\n",
    "    FA_SP_model, FA_SP_test_predictions = train_linear_model(FA_SP_dataset)\n",
    "    \n",
    "    MAE = score_models(\n",
    "        SU_test_y, \n",
    "        SU_test_predictions,\n",
    "        FA_SP_test_y,\n",
    "        FA_SP_test_predictions\n",
    "    )\n",
    "    \n",
    "    results['test_set_scores'].append(MAE)\n",
    "    results['SU_models'].append(SU_model)\n",
    "    results['FA_SP_models'].append(FA_SP_model)\n",
    "    results['test_features'].extend(SU_dataset['test_x'])\n",
    "    results['test_features'].extend(FA_SP_dataset['test_x'])\n",
    "    results['test_labels'].extend(SU_dataset['test_y'])\n",
    "    results['test_labels'].extend(FA_SP_dataset['test_y'])\n",
    "    results['test_predictions'].extend(SU_test_predictions)\n",
    "    results['test_predictions'].extend(FA_SP_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507915c3-5a1d-454c-9344-4185c15339b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "pkl_filename = f'{conf.RESULTS_PATH}{conf.SIMPLE_LINEAR_MODEL_RESULTS_FILE}'\n",
    "\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a6c0a9-cc7b-47fa-aa13-662331a626fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of MAE scores from each model\n",
    "sns.displot(results['test_set_scores'], kind=\"kde\")\n",
    "plt.xlabel('Mean absolute error')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc2ba62-5387-404b-b66e-93cc997788bc",
   "metadata": {},
   "source": [
    "Looks great, now lets set up to make predictions from the model ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc7c458-6bab-48ce-99a6-a37cca116678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty list to hold summer predictions\n",
    "SU_predictions = []\n",
    "\n",
    "SU_x_timestamp = SU_x.values.astype(np.int64) // 10 ** 9\n",
    "SU_x_timestamp = np.array(SU_x_timestamp).reshape(-1, 1)\n",
    "\n",
    "for model in results['SU_models']:\n",
    "    predicted_enrollment = model.predict(SU_x_timestamp)\n",
    "    SU_predictions.append(predicted_enrollment)\n",
    "\n",
    "# Average the predictions from each model\n",
    "SU_predicted_enrollment = np.mean(np.array(SU_predictions), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091cf888-f587-40e5-9d15-b75eb72d6917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty list to hold fall-spring predictions\n",
    "FA_SP_predictions = []\n",
    "\n",
    "FA_SP_x_timestamp = FA_SP_x.values.astype(np.int64) // 10 ** 9\n",
    "FA_SP_x_timestamp = np.array(FA_SP_x_timestamp).reshape(-1, 1)\n",
    "\n",
    "for model in results['FA_SP_models']:\n",
    "    predicted_enrollment = model.predict(FA_SP_x_timestamp)\n",
    "    FA_SP_predictions.append(predicted_enrollment)\n",
    "\n",
    "# Average the predictions from each model\n",
    "FA_SP_predicted_enrollment = np.mean(np.array(FA_SP_predictions), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4111622-1889-4052-a586-725a74abfc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.scatter(SU_y, SU_predicted_enrollment, c='green', label='Summer')\n",
    "plt.scatter(FA_SP_y, FA_SP_predicted_enrollment, c='black', label='Fall, Spring')\n",
    "plt.legend(loc='upper left')\n",
    "plt.axis([None, None, 0, 30000])\n",
    "fig.suptitle('Census Enrollment', fontsize=20)\n",
    "plt.xlabel('Actual enrollment', fontsize=18)\n",
    "plt.ylabel('Predicted enrollment', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ff2dec-6660-46cf-b4c9-b3a99fe8e707",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE = score_models(\n",
    "    SU_y, \n",
    "    SU_predicted_enrollment,\n",
    "    FA_SP_y,\n",
    "    FA_SP_predicted_enrollment\n",
    ")\n",
    "\n",
    "print(f'Ensamble MAE: {int(MAE)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4135fa5b-1b25-44c4-b55b-3cb5d6b934af",
   "metadata": {},
   "source": [
    "Last thing before we move on - lets set up a confidence interval around an example prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cbd5b8-841c-4cdb-b278-a64634a5eb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick one point to predict\n",
    "target = list(FA_SP_x_timestamp)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b08bde7-d154-423d-861c-295840021528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty list to hold fall-spring predictions\n",
    "FA_SP_predictions = []\n",
    "\n",
    "for model in results['FA_SP_models']:\n",
    "    predicted_enrollment = model.predict([target])\n",
    "    FA_SP_predictions.extend(predicted_enrollment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0415a38-a0cb-4be8-99be-92b1746ddcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of predictions from each model\n",
    "sns.displot(FA_SP_predictions, kind=\"kde\")\n",
    "plt.xlabel('Mean absolute error')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214b9ede-a0d7-45c6-a2b3-255238b8ed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "\n",
    "mean = np.mean(FA_SP_predictions)\n",
    "low, high = st.norm.interval(alpha=0.95, loc=np.mean(FA_SP_predictions), scale=st.sem(FA_SP_predictions))\n",
    "\n",
    "print(f'Mean: {int(mean)}, 95% CI: {int(low)}-{int(high)}')\n",
    "print(f'True value: {int(list(FA_SP_y)[3])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609ae030-25c6-4218-be09-0141b0736d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
